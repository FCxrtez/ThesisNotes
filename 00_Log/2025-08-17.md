# FPNew
empezamos a trabajar con esa unidad en mente.
En base a la arquitectura se me ocurrio la posibilidad de optimizar la unidad para un tipo de benchmark especifico, por ejemplo para workloads relacionados a IA/matrices, cambiando la distribuccion de las slices dentro de cada grupo.
N tipos de formatos en dise√±o
N slices por grupo + 1 "universal merged"
Podriamos dejar mas slices para un tipo de FP en base a alguna distribucion sobre las instrucciones tomadas en workloads en 8-bit
De esta manera la tesis logra tocar un punto mas de relevancia cientifica, sobre el rendimiento de IA en hw especifico. Dejando algunas unidades de calculo universal de manera que sea "completa" la FPU.
Este es un tipo de idea utilizado comunmente en arquitectura? Investigar en Hennesy-Patterson?
Puede que sea una burrada.
Puede no valerlo y llegar a resultados extremadamente malos, idea rara.
Yendo mas alla, se podria cuestionar la cantidad de slices por grupo de computo, dejando nuevamente unidades universales y asignando una mayor cantidad de slices a calculos comunes.
De la manera que trabaja ahora la FPU es que estos distintas slices pueden calcular en paralelo mientras que sean distintos formatos. Puede que este cambio que quiero introducir genere demasiada latencia para los otros formatos, los que dejen de tener slice exclusiva.
Siendo que el paper de FPNew hace enfeasis en su bajo de consumo energetico, puede que al optimizar y acelerar calculos se logre un menor consumo energetico por la rapidez del calculo (menor tiempo total)?
Para identificar si sera una buena idea, buscar primero la distribucion de operaciones, buscar benchmarks disponibles
